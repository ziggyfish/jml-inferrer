\section{Discussion}

The results demonstrate that automated specification inference is a powerful tool for supporting software evolution and maintenance, particularly in distributed systems. By embedding machine-verifiable contracts into shared libraries, our tool provides clear benefits to developers working across microservices, modular architectures, and legacy systems. These contracts act as executable specifications automatically checked during development and integration. When a developer updates a microservice, shared library contracts immediately highlight violations of expected behavior, preventing faulty deployments. In modular systems, they ensure that changes in one component do not break dependent interfaces. In legacy systems, contracts provide a safety net by formally specifying expected behavior, enabling automated test generation and fault detection even when documentation is incomplete. Overall, developers can use these contracts to guide coding, validate integration, and maintain correctness throughout the software lifecycle.

A key finding is the improvement in mutation coverage and unit test completeness across diverse method categories. \emph{Control Flow Structures}, \emph{Factory \& Delegate Patterns}, and \emph{Accessors \& Mutators} achieved mutation coverage exceeding 94\%, showing that inferred specifications effectively verify correctness across different behavior types — a crucial factor in maintaining reliable software.

Unlike prior work relying on manually written specifications~\cite{hasan_formal_2015, andronick_large-scale_2012} or natural language documentation~\cite{toradocu2016, jdoctor2018}, our method provides an automated, scalable solution integrated directly into modern toolchains. The inferred specifications are derived from program logic, ensuring consistency with implementation and mitigating documentation drift.

Beyond improved testing, the tool contributes to the \textit{evolutionary lifecycle} of distributed software. As systems change and teams rotate, maintaining confidence in shared behavior remains a challenge. Our approach addresses this by generating \emph{contractual documentation} embedded within reusable libraries, enabling validation even when source code is unavailable — a common scenario in microservice architectures.

These findings support the view that formal methods can deliver practical value when automated appropriately. By reducing the effort to generate specifications and integrating them into CI/CD pipelines, our tool bridges the gap between formal verification and agile development~\cite{matichuk_cost_2015, martin2008clean}.

Several limitations warrant discussion. While the approach achieves strong results across diverse function types, its effectiveness is lower for highly dynamic or side-effect-heavy methods, such as event-driven handlers or complex I/O. The computational cost of weakest precondition analysis also grows with control-flow complexity. Although acceptable in our evaluation, optimizing inference for industrial-scale systems remains an important direction for future work.

Finally, while we demonstrated test generation and mutation resilience as measurable benefits, additional developer studies (e.g., comprehension or onboarding tasks) would help validate the real-world utility of inferred specifications from a human-factors perspective~\cite{gamma1994design, fowler2004refactoring}.

In summary, the proposed tool improves both test robustness and long-term maintainability. It provides a foundation for research into specification-based software evolution and represents a step toward scalable formal reasoning tools that integrate naturally into modern engineering workflows.

\section{Related Works}

Formal specification inference has been a prominent area of research in software verification. Numerous studies focus on the automated generation of specifications to enhance software reliability and testing. Several approaches exist for inferring specifications, including:

One of the foundational approaches to formal verification is theorem proving and model checking. Hasan and Tahar \cite{hasan_formal_2015} provide an overview of formal verification techniques, highlighting the role of theorem provers in ensuring software correctness. However, theorem proving traditionally requires manually written formal specifications, which can be costly and time-consuming. Similarly, the work by Andronick et al. \cite{andronick_large-scale_2012} describes large-scale formal verification in industry settings, illustrating the challenges associated with manually crafting specifications along with the high costs involved in the verification process.

D'Silva et al. \cite{dsilva_survey_2008} provide a comprehensive survey of automated formal verification techniques. They note that while static analysis methods, including weakest precondition propagation and symbolic execution, have been employed for specification inference, these techniques often encounter challenges related to scalability and the management of complex real-world codebases. Easterbrook and Callahan \cite{easterbrook_formal_1998} discuss the validation of partial specifications, which is relevant to our study. However, their approach does not leverage automatic inference techniques, rendering it less adaptable to contemporary software development environments.

A more recent development in specification inference is the use of shared libraries in distributed systems to standardize communication and ensure data integrity. De Toledo et al. \cite{de_toledo_improving_2020} explore how microservices leverage shared libraries to maintain consistency across services. Our study builds upon their findings by integrating inferred specifications into shared libraries. This integration enhances the reliability of these libraries and supports automated verification within microservice architectures. This work extends their findings by embedding inferred specifications into shared libraries, thereby enhancing their reliability and supporting automated verification in microservice architectures.

Matichuk et al. \cite{matichuk_cost_2015} conducted an empirical study on the cost-effectiveness of formal verification, concluding that the manual development of specifications remains expensive despite the availability of theorem provers. Our study addresses this cost issue by automating specification inference, thereby reducing reliance on manual intervention.

Another key issue in software testing is the adequacy of unit tests. Zhu et al. \cite{zhu_software_1997} and Pinto et al. \cite{pinto_inadequate_2017} highlight the limitations of unit testing, which stem from insufficient test coverage and the overconfidence of developers in existing tests. Our study builds upon this by demonstrating that inferred specifications significantly enhance test coverage and robustness, particularly in distributed systems where traditional unit testing poses challenges.

\subsection{Complementary Approaches: Toradocu/Jdoctor and PreInfer}

The Toradocu tool~\cite{toradocu2016}, along with its enhanced version Jdoctor~\cite{jdoctor2018}, exemplifies a notable application of natural language processing (NLP) to extract exception-related preconditions from Java code. These tools interpret structured natural language within Javadoc comments to infer preconditions, which are expressed as Java Boolean conditions. Such inferred conditions can be used to automatically generate test oracles, guide unit test generation, or enrich formal specifications, ensuring that software behaves as documented. In evaluations using popular Java libraries, Jdoctor demonstrated a recall of 83\% and a precision of 92\%, underscoring its effectiveness in recovering documented behavior that can be directly leveraged for testing and verification.

Our approach and Toradocu/Jdoctor serve complementary roles:

\begin{itemize}
    \item Toradocu and Jdoctor rely on the presence of structured documentation, enabling them to extract preconditions effectively when they are described. However, this dependence on natural language also introduces limitations in terms of precision, as natural language can be inherently ambiguous.
    
    \item In contrast, our method infers specifications by analyzing the actual program logic through static techniques. This allows for high precision --- inferred conditions are correct by construction --- though it may lead to lower recall when some behaviors are not explicitly represented in the control flow. This trade-off makes our method especially suited to environments where correctness is critical, such as distributed or microservice-based systems.
\end{itemize}

Importantly, only a subset of the exception preconditions discovered by our technique is actually present in Javadoc comments. For example, consider a method that parses user input and throws a \texttt{NumberFormatException} when the input is invalid. This exception may not be documented in the Javadoc, so a tool like Jdoctor would not recover it. In contrast, our method can automatically infer this precondition from the code, revealing that the input must satisfy a numeric format constraint. This underscores a limitation of comment-based approaches like Jdoctor: they can only recover what developers have chosen to document. By uncovering latent specifications, our method provides a more complete understanding of exceptional behavior.

PreInfer \cite{preinfer2017} is another relevant contribution, focusing on the C\# language. It infers preconditions by analyzing failing executions using symbolic execution, specifically via the Pex testing framework. PreInfer is capable of synthesizing intricate conditions, including disjunctions and quantified properties over arrays. In contrast to our work, PreInfer occupies a different region of the design space:

\begin{itemize}
    \item PreInfer is optimized for identifying complex conditions in computationally intensive functions, often found in data structure and algorithm implementations. While Pex systematically explores execution paths, the sheer number of possible paths in complex or recursive functions can make exhaustive analysis infeasible. As a result, some paths may not be explored within practical time or resource limits, and the inferred conditions may not be guaranteed to be complete or sound.
    
    \item Our technique is engineered for scalability and precision, aiming to infer simpler, highly reliable preconditions. This focus makes it more applicable to large-scale software systems, where individual units may be less complex but system-wide reliability is crucial.
\end{itemize}

\subsection{Extending the Capacity of Existing Work}

Our work extends prior specification inference tools such as Toradocu/Jdoctor and PreInfer by focusing on automatic inference of formal specifications through weakest precondition (WP) analysis. While Toradocu and Jdoctor extract exception preconditions from Javadoc comments, their effectiveness is limited by the availability and clarity of documentation. In contrast, our approach infers precise specifications directly from source code, making it suitable for large, real-world systems where documentation is sparse or outdated.

PreInfer infers complex preconditions in C\# using symbolic execution via Pex but suffers from incomplete coverage due to runtime path exploration. Our WP-based static analysis instead emphasizes soundness and scalability, tailored for Java environments—particularly distributed and microservice systems—where consistent inter-service contracts are critical.

A key contribution of our work is integrating inferred specifications into shared libraries, producing formalized interfaces portable across microservices. These specifications encode method behavior as preconditions and postconditions, enabling compatibility checks and early detection of integration issues even without source access. Automated reasoning tools can also validate interactions between services by ensuring postconditions align with caller assumptions.

Empirically, this approach increased test generation by 35–193\% and raised mutation coverage above 94\% across key method categories. Overall, our scalable, language-agnostic framework grounded in formal semantics advances automated verification and improves test coverage, reliability, and CI/CD integration for distributed software systems.